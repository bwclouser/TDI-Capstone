{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0750a0",
   "metadata": {},
   "source": [
    "Utility Funcitons for loading and handling processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f04d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gp\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921ede29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff58188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991d865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/benjamin/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/07/26 12:15:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/26 12:15:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/26 12:15:32 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext('local[*]','temp')\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddf0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=np.dtype([('id',np.ulonglong),('start year',np.short),('start month',np.byte),('start day',np.byte),('start hour',np.byte),('start minute',np.byte),('start julian',np.double),('end year',np.short),('end month',np.byte),('end day',np.byte),('end hour',np.byte),('end minute',np.byte),('trip seconds',np.uint32),('trip miles',np.single),('pickup census tract',np.ulonglong),('dropoff census tract',np.ulonglong),('pickup community area',np.byte),('dropoff community area',np.byte),('fare',np.single),('tip',np.single),('addcharge',np.single),('trip total',np.single),('st auth',np.byte),('pool',np.byte),('pickup lat',np.double),('pickup lon',np.double),('dropoff lat',np.double),('dropoff lon',np.double)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97200d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array(x):\n",
    "    array=np.frombuffer(bytes(x),dtype=dt)\n",
    "    return array.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857b2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_range(start_year,start_month,end_year,end_month,path='/media/benjamin/Data/Chicago_Transit/TNP/'):\n",
    "    dt=np.dtype([('id',np.ulonglong),('start year',np.short),('start month',np.byte),('start day',np.byte),('start hour',np.byte),('start minute',np.byte),('start julian',np.double),('end year',np.short),('end month',np.byte),('end day',np.byte),('end hour',np.byte),('end minute',np.byte),('trip seconds',np.uint32),('trip miles',np.single),('pickup census tract',np.ulonglong),('dropoff census tract',np.ulonglong),('pickup community area',np.byte),('dropoff community area',np.byte),('fare',np.single),('tip',np.single),('addcharge',np.single),('trip total',np.single),('st auth',np.byte),('pool',np.byte),('pickup lat',np.double),('pickup lon',np.double),('dropoff lat',np.double),('dropoff lon',np.double)])\n",
    "    \n",
    "    #Calculate month and year ranges\n",
    "    nmonths=(end_year-start_year-1)*12.+(12.-start_month+1)+end_month\n",
    "    yrs=(start_year+np.floor((start_month+np.arange(0,nmonths)-1)/12.)).astype(int)\n",
    "    mos=(np.floor((np.mod(start_month+np.arange(nmonths)-1,12)+1 ))).astype(int)\n",
    "    \n",
    "    #construct list of file names\n",
    "    fnames=''\n",
    "    if nmonths > 1:\n",
    "        for i in np.arange(0,nmonths,dtype=np.int16):\n",
    "            fnames+=(path+\"{0:04d}{1:02d}\".format(yrs[i],mos[i])+'TNP.dat')\n",
    "            if i != nmonths-1:\n",
    "                fnames+=','\n",
    "    else:\n",
    "        fnames=path+\"{0:04d}{1:02d}\".format(yrs,mos)+'TNP.dat'\n",
    "        \n",
    "    #load binary records into rdd given record length\n",
    "    rdd=sc.binaryRecords(fnames,104)\n",
    "    out=rdd.map(read_array)\n",
    "    df=out.toDF(['id','start year','start month','start day','start hour','start minute','start julian','end year','end month','end day','end hour','end minute','trip seconds','trip miles','pickup census tract','dropoff census tract','pickup community area','dropoff community area','fare','tip','addcharge','trip total','st auth','pool','pickup lat','pickup lon','dropaff lat','dropoff lon'])\n",
    "    out.unpersist()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe3efba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def area_out(df,ca,to_pandas=True):\n",
    "    with_out=df.groupby(['start year','start month','start day','start hour','start julian','pickup community area']).count()\n",
    "    out_area=with_out.where(with_out['pickup community area']==ca)\n",
    "    out_area_sort=out_area.sort(['start year','start month','start day','start hour'])\n",
    "    if to_pandas:\n",
    "        outdf=out_area_sort.toPandas()\n",
    "        outdf=outdf.rename(columns={'start year':'year','start month':'month','start day':'day','start hour':'hour'})\n",
    "    else:\n",
    "        outdf=out_area_sort.withColumnRenamed('start year','year').withColumnRenamed('start month','month').withColumnRenamed('start day','day').withColumnRenamed('start hour','hour')\n",
    "    return outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6943250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_time_count(df,yr,mo,dy,hr):\n",
    "        one_time=df.where((df['start year']==yr) & (df['start month']==mo) & (df['start day']==dy) & (df['start hour']==hr))\n",
    "        cnt=one_time.groupby(['pickup community area']).count().toPandas()\n",
    "        return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee6687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chicago(counts):\n",
    "    #expects geopandas dataframe with chicago boundary information\n",
    "    #and counts as a pandas dataframe\n",
    "    chicago=gp.read_file('/media/benjamin/Data/Chicago_Transit/Shapes/geo_export_43aec312-120e-4284-b1ca-b89761679d63.shp')\n",
    "    chicago['pickup community area']=chicago['area_num_1'].astype(np.int32)\n",
    "    with_count=chicago.merge(counts,on='pickup community area',how='left')\n",
    "    fix, ax = plt.subplots(1,1) \n",
    "    with_count.plot(column='count',ax=ax,legend=True,legend_kwds={'label':'Pickup Count'})\n",
    "    return with_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0725eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefficients(counts):\n",
    "    \n",
    "    to_fit=counts.withColumn('twhrsine',F.sin(2*3.14159*F.col('start julian')*2.)).withColumn('twhrcos',F.cos(2*3.14159*F.col('start julian')*2.)).withColumn('daysine',F.sin(2*3.14159*F.col('start julian'))).withColumn('daycos',F.cos(2*3.14159*F.col('start julian'))).withColumn('weeksine',F.sin(2*3.14159*F.col('start julian')/7.)).withColumn('weekcos',F.cos(2*3.14159*F.col('start julian')/7.))\n",
    "    va=VectorAssembler(inputCols = ['twhrsine','twhrcos','daysine','daycos','weeksine','weekcos'],outputCol = 'features')\n",
    "    lr=LinearRegression(regParam=0.1)\n",
    "    va_to_fit = va.transform(to_fit)\n",
    "    final = va_to_fit.selectExpr(['features','count as label'])\n",
    "    lr_model=lr.fit(final)\n",
    "    return lr_model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(time):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161dbe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_in_range(2020,6,2022,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/26 12:29:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/07/26 12:29:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/07/26 12:29:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/07/26 12:29:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 185:================================================>   (199 + 15) / 214]\r"
     ]
    }
   ],
   "source": [
    "NbdModels={}\n",
    "for i in np.arange(1,78):\n",
    "    cnt=area_out(df,int(i),to_pandas=False)\n",
    "    model=get_coefficients(cnt)\n",
    "    NbdModels[i]=model\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc6def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
